{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our hatsTrees that have the interesting physical variables calculated, let's do some analysis with them. To combine our MC background samples, we will need to compute weights for them. Fortunately, we have these defined in python `.ini` files.\n",
    "\n",
    "`.ini` files are a standard format for python configuration files. They have a simple syntax and are quite flexible -- this is another example of where python can help us from falling in the trap of re-inventing the wheel by writing custom code for every simple task, like parsing text files.\n",
    "\n",
    "Let's take a look at `hatsConfig.ini`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat hatsConfig.ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ConfigParser import RawConfigParser\n",
    "config = RawConfigParser()   \n",
    "config.optionxform = str       # Last two lines are done because ConfigParser will not preserve case\n",
    "config.read(\"hatsConfig.ini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a nifty way to create a dict of the cross sections and number of events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crossSections = dict([sample, float(xsec)] for sample, xsec in config.items('hatsXsects'))\n",
    "nProcessed    = dict([sample, int(nPro)] for sample, nPro in config.items('hatsNprocessed'))\n",
    "\n",
    "from pprint import pprint\n",
    "print \"cross sections:\" \n",
    "pprint(crossSections)\n",
    "print \"number of events processed:\"\n",
    "pprint(nProcessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python `dict`s are extremely useful, because we can give descriptive names to the data they hold. Let's use our dicts to calculate the weights for our MC background samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = {}\n",
    "luminosity = 1.42    # This is just an example value\n",
    "for sample in crossSections.keys():\n",
    "    weights[sample] = luminosity * crossSections[sample]/nProcessed[sample]\n",
    "pprint(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can make dicts to hold TChains of all our data, and then draw them with weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ROOT as r\n",
    "from os import listdir, path, popen\n",
    "hatsTreesDir = \"root://cmseos.fnal.gov//store/user/hats/PyRoot/2017/hatsDijetTrees\"\n",
    "hatsChains = {}\n",
    "for sample in crossSections.keys():\n",
    "    sampleDir = hatsTreesDir + \"/hatsTrees_\" + sample\n",
    "    chain = r.TChain('hatsDijets')\n",
    "    for hatsFile in filter(None,popen(\"xrdfs root://cmseos.fnal.gov/ ls -u \"+sampleDir).read().split('\\n')):\n",
    "        chain.Add(hatsFile)\n",
    "    hatsChains[sample] = chain\n",
    "pprint(hatsChains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try to make weighted histograms of all the MC backgrounds using TChain.Draw(), and put them into a stackplot. Here we run into a classic pyROOT gotcha: it's not easy to prevent root from garbage collecting your histograms. It's best to keep them in an array that isn't within the scope of a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hists = {}\n",
    "for sample in crossSections.keys():\n",
    "    varNames=[]\n",
    "    for var in hatsChains[sample].GetListOfBranches():\n",
    "        varNames.append(var.GetName())\n",
    "    for varName in varNames:\n",
    "        histLabel = \"%s_%s\" % (varName, sample)\n",
    "        hists[histLabel]=r.TH1F(histLabel, histLabel, 100, 0, 0)\n",
    "        hatsChains[sample].Draw(\"%s>>%s\" % (varName, histLabel))\n",
    "\n",
    "pprint(hists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've made histograms of all our variables in all our samples, we can put together stack plots of them all. We will leave that as an exercise to work on for the rest of the HATS. The histograms are organized in a dictionary that you should be able to navigate easily using their keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "canvas = r.TCanvas()\n",
    "hists[\"cosThetaStar_QCD_HT1000to1500\"].Draw()\n",
    "canvas.Draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
