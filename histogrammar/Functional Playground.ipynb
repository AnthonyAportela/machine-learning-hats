{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "require(['notebook'],\n",
       "  function() {\n",
       "    IPython.CodeCell.config_defaults.highlight_modes['magic_text/x-c++src'] = {'reg':[/^%%cpp/]};\n",
       "    console.log(\"JupyROOT - %%cpp magic configured\");\n",
       "  }\n",
       ");\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.08/04\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import ROOT\n",
    "tcanvas = ROOT.TCanvas(\"TCanvasName\", \"TCanvasTitle\", 800, 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Playground\n",
    "\n",
    "Let's back up and introduce the project properly.\n",
    "\n",
    "No programming language is good at everything, and both C++ and Python are bad at parallel processing. Developing a good langauge for parallel processing is a frontier of computer science and has been for the past 20 years or so.\n",
    "\n",
    "A few concepts are emerging as important for parallel processing:\n",
    "\n",
    "   * **immutable, composable data**\n",
    "   * **functionals instead of loops**\n",
    "   * lazy evaluation\n",
    "   * (actor-like isolation)\n",
    "   * (asynchronous calls, callbacks, futures/promises)\n",
    "   * (reactive APIs)\n",
    "\n",
    "But only the first two or three are, in my opinion, relevant for _data analysis._\n",
    "\n",
    "### Immutable, composable data\n",
    "\n",
    "\"Immutable\" means that a quantity can't be changed after it has been created.\n",
    "\n",
    "**Examples:**\n",
    "\n",
    "   * In all programming languages, numbers are immutable. (Pascal let you change the definition of numbers like \"4\", but nothing about their internal structure. And even then, it was widely regarded as a terrible idea.)\n",
    "   * In Python but not C++, strings are immutable. Operating on a string in Python always creates a new string; the old one is either kept or garbage collected. In C++, you can change individual characters of a string, which makes string processing much more complicated.\n",
    "   * In \"purely functional\" languages like Haskell, _all_ data are immutable. Every little change requires a new data structure.\n",
    "\n",
    "\"Composable\" means that you can use existing data to make new data. When you can't change data in-place, composing becomes the primary way of operating on data.\n",
    "\n",
    "**Why is this important?**\n",
    "\n",
    "Because if you have multiple computers looking at the same data, they are necessarily looking at different _copies_ of the data. Any transfer of data through space is, strictly speaking, a copy. The original may or may not be deleted after or during the copy.\n",
    "\n",
    "If a processor is allowed to change its copy of the data in-place, then the others either become out of date or have to be updated. Pausing processing to update a variable's state slows down processing, defeating the purpose of parallel processing. Thus, it's good to avoid it.\n",
    "\n",
    "### Functionals instead of loops\n",
    "\n",
    "A \"functional\" is a function that takes functions as arguments. (Other words for this are \"functors\" and \"higher-order functions,\" but \"functional\" is used more in a physics context.)\n",
    "\n",
    "You may remember functionals from classical or quantum mechanics: a Lagrangian is a functional that takes a field and its derivative as arguments, both of which are functions defined on all space-time, and returns a real number.\n",
    "\n",
    "Two functionals have become very popular recently: `map` and `reduce`. The Hadoop framework, also known as \"map-reduce,\" implements the `map` and `reduce` functionals over a cluster of networked computers, so that a data analyst only has to write their problem as functions to pass into `map` and `reduce` to submit their job.\n",
    "\n",
    "Below, we'll play with `map`, `reduce`, and several other useful functionals.\n",
    "\n",
    "### Lazy evaluation\n",
    "\n",
    "Sometimes relevant for data analysis. A programming task can either be executed exactly where it is written or it may be delayed for later execution. \"Lazy evaluation\" is when the programming environment executes an expression at the latest possible time.\n",
    "\n",
    "This concept was integrated into CMSSW's pipelines, so that producers are only invoked when and if their data are needed.\n",
    "\n",
    "In Python, we see this distinction between lists, which are fully evaluated data in memory, and generators, which produce data on demand (lazily).\n",
    "\n",
    "When data are evaluated lazily, they don't need to be finite. We'll be working with an infinite stream of CMS events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional programming in Python\n",
    "\n",
    "The next three cells augment Python to make it more functional. We'll use it to tinker with data analysis in a functional setting as a way of motivating why the Histogrammar library is designed the way it is.\n",
    "\n",
    "Go ahead and evaluate these three cells. I could have put these commands in an external Python module, but thought it would be better if I didn't hide anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Please ignore the man behind the curtain...\n",
    "#### This is just a hack to add new methods to Python's built-in types.\n",
    "\n",
    "import ctypes\n",
    "\n",
    "if hasattr(ctypes.pythonapi, \"Py_InitModule4_64\"):\n",
    "    Py_ssize_t = ctypes.c_int64\n",
    "else:\n",
    "    ctypes.c_int\n",
    "\n",
    "class PyObject(ctypes.Structure): pass\n",
    "PyObject._fields_ = [(\"ob_refcnt\", Py_ssize_t), (\"ob_type\", ctypes.POINTER(PyObject))]\n",
    "\n",
    "class SlotsPointer(PyObject):\n",
    "    _fields_ = [(\"dict\", ctypes.POINTER(PyObject))]\n",
    "\n",
    "def proxy_builtin(cls):\n",
    "    name = cls.__name__\n",
    "    slots = getattr(cls, \"__dict__\", name)\n",
    "\n",
    "    pointer = SlotsPointer.from_address(id(slots))\n",
    "    namespace = {}\n",
    "\n",
    "    ctypes.pythonapi.PyDict_SetItem(\n",
    "        ctypes.py_object(namespace),\n",
    "        ctypes.py_object(name),\n",
    "        pointer.dict\n",
    "    )\n",
    "\n",
    "    return namespace[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function __main__.<lambda>>,\n",
       " <function __main__.<lambda>>,\n",
       " [],\n",
       " <function __main__.<lambda>>,\n",
       " <function __main__.<lambda>>,\n",
       " <function __main__.<lambda>>,\n",
       " <function __main__.<lambda>>,\n",
       " <function __main__.<lambda>>,\n",
       " <function __main__.<lambda>>,\n",
       " <function __main__.<lambda>>,\n",
       " <function __main__.<lambda>>,\n",
       " <function __main__.<lambda>>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Attach functional methods to the Python \"list\" type.\n",
    "\n",
    "def sizer(lst):\n",
    "    \"\"\"\n",
    "    Return the length of the list.\n",
    "    \n",
    "    Example: [1, 2, 3, 4, 5].size == 5\n",
    "    \n",
    "    (For convenience, since everything else is attached at the end of a chain of methods.)\n",
    "    \"\"\"\n",
    "    return len(lst)\n",
    "\n",
    "def taker(lst):\n",
    "    \"\"\"\n",
    "    Return the first n elements of the list.\n",
    "    \n",
    "    Example: [1, 2, 3, 4, 5].take(3) == [1, 2, 3]\n",
    "    \"\"\"\n",
    "    if isinstance(lst, list):\n",
    "        return lambda n: lst[:n]\n",
    "    else:\n",
    "        def gen(n):\n",
    "            for i, x in enumerate(lst):\n",
    "                yield x\n",
    "                if i + 1 >= n: break\n",
    "        return gen\n",
    "\n",
    "def mapper(lst):\n",
    "    \"\"\"\n",
    "    Apply a given function to each element of this list.\n",
    "    \n",
    "    The function must take one argument.\n",
    "    \n",
    "    Examples: [1, 2, 3, 4, 5].map(f) == [f(1), f(2), f(3), f(4), f(5)]\n",
    "              [1, 2, 3, 4, 5].map(lambda x: x + 100) == [101, 102, 103, 104, 105]\n",
    "    \"\"\"\n",
    "    if isinstance(lst, list):\n",
    "        return lambda f: [f(x) for x in lst]\n",
    "    else:\n",
    "        return lambda f: (f(x) for x in lst)\n",
    "\n",
    "def flattener(lst):\n",
    "    \"\"\"\n",
    "    Turn a list-of-lists into a list of all elements. Only reduces one level of structure.\n",
    "        \n",
    "    Examples: [[1, 2], [3, 4, 5]].flatten == [1, 2, 3, 4, 5]\n",
    "              [[1, 2], [3, [4, 5]]].flatten == [1, 2, 3, [4, 5]\n",
    "    \"\"\"\n",
    "    if isinstance(lst, list):\n",
    "        return sum(lst, [])\n",
    "    else:\n",
    "        def gen():\n",
    "            for x in lst:\n",
    "                for y in x:\n",
    "                    yield y\n",
    "        return gen()\n",
    "\n",
    "def flatmapper(lst):\n",
    "    \"\"\"\n",
    "    Same as [...].map(f).flatten, but these two operations are frequently done together.\n",
    "    \n",
    "    The function must take one argument.\n",
    "    \n",
    "    In general: [...].flatmap(f) == [...].map(f).flatten\n",
    "    \n",
    "    Example: [1, 2, 3, 4, 5].flatmap(lambda x: [x, x + 100]) == [1, 101, 2, 102, 3, 103, 4, 104, 5, 105]\n",
    "    \n",
    "    Flatmap is a very general operation. You can use it to expand a table, as above, or to map and filter\n",
    "    at the same time. (In the theory of monads, \"flatmap\" is the fundamental \"bind\" operation.)\n",
    "    \n",
    "    Example: [1, 2, 3, 4, 5].flatmap(lambda x: [100 + x] if x > 2 else []) == [103, 104, 105]\n",
    "    \n",
    "    You might encounter this when you want to compute something for all particles in each event, but also\n",
    "    handle the case when there are no particles after cuts. In that case, \"flatmap\" instead of \"map\" and\n",
    "    return a singleton list [result] when you have a result and an empty list [] when you don't.\n",
    "    \"\"\"\n",
    "    if isinstance(lst, list):\n",
    "        return lambda f: sum((f(x) for x in lst), [])\n",
    "    else:\n",
    "        def gen(f):\n",
    "            for x in lst:\n",
    "                for y in f(x):\n",
    "                    yield y\n",
    "        return gen\n",
    "\n",
    "def filterer(lst):\n",
    "    \"\"\"\n",
    "    Apply a given function to each element of the list and return only those that return True.\n",
    "    \n",
    "    The function must take one argument and return True or False.\n",
    "    \n",
    "    Example: [1, 2, 3, 4, 5].filter(lambda x: x > 2) == [3, 4, 5]\n",
    "    \"\"\"\n",
    "    if isinstance(lst, list):\n",
    "        return lambda f: [x for x in lst if f(x)]\n",
    "    else:\n",
    "        def gen(f):\n",
    "            for x in lst:\n",
    "                if f(x):\n",
    "                    yield x\n",
    "        return gen\n",
    "    \n",
    "def reducer(lst):\n",
    "    \"\"\"\n",
    "    Apply a given function to each element and a running tally to produce a single result.\n",
    "    \n",
    "    The function must take two arguments. The first may be an element from the list or a tally.\n",
    "    The second will always be from the list.\n",
    "    \n",
    "    Examples: [1, 2, 3, 4, 5].reduce(f) == f(f(f(f(1, 2), 3), 4), 5)\n",
    "              [1, 2, 3, 4, 5].reduce(lambda x, y: x + y) == 15\n",
    "    \"\"\"\n",
    "    return lambda f: reduce(f, lst)\n",
    "\n",
    "def aggregator(lst):\n",
    "    \"\"\"\n",
    "    Same as reduce, except start the aggregation on a given zero element.\n",
    "    \n",
    "    The function must take two arguments. The first will always be a tally and the second from the list.\n",
    "    \n",
    "    Examples: [1, 2, 3, 4, 5].aggregate(f, 0) == f(f(f(f(f(0, 1), 2), 3), 4), 5)\n",
    "              [1, 2, 3, 4, 5].aggregate(lambda x, y: x + y, 0) == 15\n",
    "              (\"a\", \"b\", \"c\").aggregate(lambda x, y: x + y, \"\") == \"abc\"\n",
    "    \"\"\"\n",
    "    return lambda f, zero: reduce(f, lst, zero)\n",
    "\n",
    "def reducerright(lst):\n",
    "    \"\"\"\n",
    "    Same as reduce, except start the nesting on the right and work left.\n",
    "    \n",
    "    The function must take two arguments. The second may be an element from the list or a tally.\n",
    "    The first will always be from the list.\n",
    "    \n",
    "    Example: [1, 2, 3, 4, 5].reduceright(f) == f(1, f(2, f(3, f(4, 5))))\n",
    "    \"\"\"\n",
    "    return lambda f: reduce(lambda a, b: f(b, a), reversed(lst))\n",
    "\n",
    "def aggregatorright(lst):\n",
    "    \"\"\"\n",
    "    Same as aggregate, except start the nesting on the right and work left.\n",
    "    \n",
    "    The function must take two arguments. The second will always be a tally and the first from the list.\n",
    "    \n",
    "    Example: [1, 2, 3, 4, 5].aggregateright(f, 0) == f(1, f(2, f(3, f(4, f(5, 0)))))\n",
    "    \"\"\"\n",
    "    return lambda f, zero: reduce(lambda a, b: f(b, a), reversed(lst), zero)\n",
    "\n",
    "def pairser(lst):\n",
    "    \"\"\"\n",
    "    Apply a given function to pairs of elements without repetition (in either order) or duplicates.\n",
    "    \n",
    "    The function must take two arguments. Both will always be elements from the list.\n",
    "    \n",
    "    If you think of the input list as a vector X, this acts on the upper trianglular part of the\n",
    "    outer product of X with X (not including diagonal).\n",
    "    \n",
    "    Alternatively, it's what you would get from these nested loops:\n",
    "    \n",
    "        for i in range(len(lst)):\n",
    "            for j in range(i + 1, len(lst)):   # j starts at i + 1\n",
    "                f(lst[i], lst[j])\n",
    "    \n",
    "    Example: [1, 2, 3, 4, 5].pairs(lambda x, y: [x, y]) == [[1, 2], [1, 3], [1, 4], [1, 5],\n",
    "                                                                    [2, 3], [2, 4], [2, 5],\n",
    "                                                                            [3, 4], [3, 5],\n",
    "                                                                                    [4, 5]]\n",
    "    \n",
    "    Use this when you want to loop over pairs of distinct pairs of elements from a single list.\n",
    "    \n",
    "    Contrast with \"table\", which is like a nested loop over several lists, for all elements.\n",
    "    \"\"\"\n",
    "    return lambda f: [f(x, y) for i, x in enumerate(lst) for y in lst[i + 1:]]\n",
    "\n",
    "def tabler(lsts):\n",
    "    \"\"\"\n",
    "    Apply a given function to all combinations of elements from all input lists.\n",
    "    \n",
    "    The function must take as many arguments as you have lists, and each will be an element from\n",
    "    each list.\n",
    "    \n",
    "    If you think of the input lists as vectors X, Y, Z, etc., this acts on each element of the\n",
    "    outer product of X with Y with Z, etc.\n",
    "    \n",
    "    Alternatively, it's what you would get from these nested loops:\n",
    "    \n",
    "        for x in lst_x:\n",
    "            for y in lst_y:\n",
    "                for z in lst_z:\n",
    "                    f(x, y, z)\n",
    "    \n",
    "    Examples: [[100, 200], [1, 2, 3]].table(lambda x, y: x + y) == [101, 102, 103, 201, 202, 203]\n",
    "    \n",
    "              [[100, 200], [10, 20], [1, 2]].table(lambda x, y, z: x + y + z) == [\n",
    "                  111, 112, 121, 122, 211, 212, 221, 222]\n",
    "\n",
    "    To illustrate the difference between table and pairs, consider the following:\n",
    "\n",
    "        [1, 2, 3].pairs(lambda x, y: [x, y]) == [[1, 2], [1, 3],\n",
    "                                                         [2, 3]]\n",
    "        \n",
    "        [[1, 2, 3], [1, 2, 3]].table(lambda x, y: [x, y]) == [[1, 1], [1, 2], [1, 3],\n",
    "                                                              [2, 1], [2, 2], [2, 3],\n",
    "                                                              [3, 1], [3, 2], [3, 3]]\n",
    "    \"\"\"\n",
    "    def buildargs(first, *rest):\n",
    "        if len(rest) == 0:\n",
    "            return [[x] for x in first]\n",
    "        else:\n",
    "            return [[x] + y for x in first for y in buildargs(*rest)]\n",
    "\n",
    "    if len(lsts) < 2:\n",
    "        raise TypeError(\"table requires at least two arguments\")\n",
    "    else:\n",
    "        first = lsts[0]\n",
    "        rest = lsts[1:]\n",
    "        return lambda f: [f(*args) for args in buildargs(first, *rest)]\n",
    "\n",
    "def zipper(lsts):\n",
    "    \"\"\"\n",
    "    Apply a function to the ith element of each list, for all i.\n",
    "    \n",
    "    The function must take as many arguments as there are lists, and each will be an element from\n",
    "    each list.\n",
    "    \n",
    "    This works just like the built-in Python zip, but applies the function to its results:\n",
    "    \n",
    "        for x, y, z in zip(lst_x, lst_y, lst_z):\n",
    "            f(x, y, z)\n",
    "    \n",
    "    Example: [[1, 2, 3], [\"a\", \"b\", \"c\"], [101, 102, 103]].zip(lambda x, y, z: (x, y, z)) == [\n",
    "                 (1, \"a\", 101), (2, \"b\", 102), (3, \"c\", 103)]\n",
    "    \"\"\"\n",
    "    if len(lsts) < 2:\n",
    "        raise TypeError(\"zip requires at least two arguments\")\n",
    "    else:\n",
    "        return lambda f: [f(*args) for args in zip(*lsts)]\n",
    "\n",
    "# attach the methods                                               force Python to notice\n",
    "proxy_builtin(list)[\"size\"] = property(sizer);                     hasattr((), \"size\")\n",
    "proxy_builtin(list)[\"take\"] = property(taker);                     hasattr((), \"take\")\n",
    "proxy_builtin(list)[\"map\"] = property(mapper);                     hasattr((), \"map\")\n",
    "proxy_builtin(list)[\"flatten\"] = property(flattener);              hasattr((), \"flatten\")\n",
    "proxy_builtin(list)[\"flatmap\"] = property(flatmapper);             hasattr((), \"flatmap\")\n",
    "proxy_builtin(list)[\"filter\"] = property(filterer);                hasattr((), \"filter\")\n",
    "proxy_builtin(list)[\"reduce\"] = property(reducer);                 hasattr((), \"reduce\")\n",
    "proxy_builtin(list)[\"aggregate\"] = property(aggregator);           hasattr((), \"aggregate\")\n",
    "proxy_builtin(list)[\"reduceright\"] = property(reducerright);       hasattr((), \"reduceright\")\n",
    "proxy_builtin(list)[\"aggregateright\"] = property(aggregatorright); hasattr((), \"aggregateright\")\n",
    "proxy_builtin(list)[\"pairs\"] = property(pairser);                  hasattr((), \"pairs\")\n",
    "proxy_builtin(list)[\"table\"] = property(tabler);                   hasattr((), \"table\")\n",
    "proxy_builtin(list)[\"zip\"] = property(zipper);                     hasattr((), \"zip\")\n",
    "\n",
    "([].take, [].map, [].flatten, [].flatmap, [].filter, [].reduce, [].aggregate,\n",
    " [].reduceright, [].aggregateright, [].pairs, [[], []].table, [[], []].zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Verify that they all work (and provide examples of their use).\n",
    "\n",
    "assert [1, 2, 3, 4, 5].take(3) == [1, 2, 3]\n",
    "\n",
    "assert [1, 2, 3, 4, 5].map(lambda x: 100 + x) == [101, 102, 103, 104, 105]\n",
    "\n",
    "assert [[1, 2], [3, 4, 5]].flatten == [1, 2, 3, 4, 5]\n",
    "assert [[1, 2], [3, [4, 5]]].flatten == [1, 2, 3, [4, 5]]\n",
    "\n",
    "assert [1, 2, 3, 4, 5].map(lambda x: [x, x + 100]) == [[1, 101], [2, 102], [3, 103], [4, 104], [5, 105]]\n",
    "assert [1, 2, 3, 4, 5].map(lambda x: [x, x + 100]).flatten == [1, 101, 2, 102, 3, 103, 4, 104, 5, 105]\n",
    "assert [1, 2, 3, 4, 5].flatmap(lambda x: [x, x + 100]) == [1, 101, 2, 102, 3, 103, 4, 104, 5, 105]\n",
    "assert [1, 2, 3, 4, 5].flatmap(lambda x: [100 + x] if x > 2 else []) == [103, 104, 105]\n",
    "\n",
    "assert [1, 2, 3, 4, 5].filter(lambda x: x > 2) == [3, 4, 5]\n",
    "\n",
    "assert [1, 2, 3, 4, 5].reduce(lambda x, y: x + y) == 15\n",
    "assert [1, 2, 3, 4, 5].reduce(lambda x, y: [x, y]) == [[[[1, 2], 3], 4], 5]\n",
    "\n",
    "assert [\"a\", \"b\", \"c\"].aggregate(lambda x, y: x + y, \"\") == \"abc\"\n",
    "assert [1, 2, 3, 4, 5].aggregate(lambda x, y: [x, y], []) == [[[[[[], 1], 2], 3], 4], 5]\n",
    "\n",
    "assert [1, 2, 3, 4, 5].reduceright(lambda x, y: [x, y]) == [1, [2, [3, [4, 5]]]]\n",
    "\n",
    "assert [1, 2, 3, 4, 5].aggregateright(lambda x, y: [x, y], []) == [1, [2, [3, [4, [5, []]]]]]\n",
    "\n",
    "assert [1, 2, 3, 4, 5].pairs(lambda x, y: [x, y]) == [[1, 2], [1, 3], [1, 4], [1, 5], [2, 3],\n",
    "                                                      [2, 4], [2, 5], [3, 4], [3, 5], [4, 5]]\n",
    "\n",
    "assert [[100, 200], [1, 2, 3]].table(lambda x, y: x + y) == [101, 102, 103, 201, 202, 203]\n",
    "assert [[100, 200], [10, 20], [1, 2]].table(lambda x, y, z: x + y + z) == [111, 112, 121, 122, 211, 212, 221, 222]\n",
    "assert [[1, 2, 3, 4, 5], [\"a\", \"b\"]].table(lambda x, y: [x, y]) == [\n",
    "    [1, \"a\"], [1, \"b\"], [2, \"a\"], [2, \"b\"], [3, \"a\"], [3, \"b\"], [4, \"a\"], [4, \"b\"], [5, \"a\"], [5, \"b\"]]\n",
    "assert [1, 2, 3].pairs(lambda x, y: [x, y]) == [[1, 2], [1, 3], [2, 3]]\n",
    "assert [[1, 2, 3], [1, 2, 3]].table(lambda x, y: [x, y]) == [[1, 1], [1, 2], [1, 3],\n",
    "                                                             [2, 1], [2, 2], [2, 3],\n",
    "                                                             [3, 1], [3, 2], [3, 3]]\n",
    "\n",
    "assert [[1, 2, 3], [\"a\", \"b\", \"c\"], [101, 102, 103]].zip(lambda x, y, z: [x, y, z]) == [\n",
    "    [1, \"a\", 101], [2, \"b\", 102], [3, \"c\", 103]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some functionals to play with\n",
    "\n",
    "The `list` data type now has 13 new methods:\n",
    "\n",
    "   * `[1, 2, 3, 4, 5].size` returns the size of the list, `5` (for convenience, not actually a functional).\n",
    "   * `[1, 2, 3, 4, 5].take(3)` returns the first three elements, `[1, 2, 3]` (for convenience, not actually a functional).\n",
    "   * `[1, 2, 3, 4, 5].map(lambda x: x**2)` is the first functional: it applies the function `lambda x: x**2` to each element and makes a new list `[1, 4, 9, 16, 25]`.\n",
    "   \n",
    "You're probably familiar with the `def` syntax for making Python functions; if you haven't seen `lambda` before, it's a short-hand for making a function without the formality of naming it or using multiple lines. Try it out in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16, 25]\n",
      "[1, 4, 9, 16, 25]\n"
     ]
    }
   ],
   "source": [
    "def square(x):\n",
    "    return x**2\n",
    "\n",
    "print [1, 2, 3, 4, 5].map(square)\n",
    "print [1, 2, 3, 4, 5].map(lambda x: x**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   * `[1, 2, 3, 4, 5].filter(lambda x: x > 2)` applies a cut on the list, returning `[3, 4, 5]`. This is a very important functional, but pretty simple, too.\n",
    "   * `[[1, 2], [3, 4, 5]].flatten` removes a layer of structure from a list, in this case returning `[1, 2, 3, 4, 5]`. That can be useful if you're turning a collection of events (containing many particles) into a \"flattened\" collection of particles (without regard for event boundaries). It's also useful for understanding what the next functional does...\n",
    "   * `[1, 2, 3, 4, 5].flatmap(lambda x: [x, x + 100])` does `.map(...).flatten` in one step, producing `[1, 101, 2, 102, 3, 103, 4, 104, 5, 105]`. You'll find that this is surprisingly useful. For instance,\n",
    "   \n",
    "```\n",
    "def dimuon(event):\n",
    "    if event.muons.size < 2:\n",
    "        return []\n",
    "    else:\n",
    "        mu1, mu2 = event.muons[:2]\n",
    "        return [(mu1 + mu2).mass]\n",
    "\n",
    "events.flatmap(dimuon)\n",
    "```\n",
    "\n",
    "computes dimuon masses from each event that has at least two muons and nothing from the rest. Returning either a singleton list with your answer or an empty list allows you to filter and map at the same time. (If you're interested in theory, `flatmap` is of foundational importance as the \"bind\" operation of a [monad](https://en.wikipedia.org/wiki/Monad_%28functional_programming%29)).\n",
    "\n",
    "The next four functionals are tightly related: they're all ways of turning a list of data into a single datum. Histogramming is an example of that: you take a zillion events and turn it into a fixed-size data structure, maybe a 100-bin histogram. Histogrammar is really just a collection of fancy `aggregate` methods.\n",
    "\n",
    "   * `[1, 2, 3, 4, 5].reduce(lambda x, y: x + y)` applies the given function to pairs of data iteratively, like this:\n",
    "\n",
    "```\n",
    "          f(f(f(f(1, 2), 3), 4), 5)\n",
    "```\n",
    "\n",
    "In this case, the operation `f` is to add pairs, and so the result is `15`.\n",
    "\n",
    "   * `[1, 2, 3, 4, 5].reduceright(f)` does `f(1, f(2, f(3, f(4, 5))))`, which only matters if `f` is not associative (a bad idea; I hope we get a chance to see why) or the dataset is infinite.\n",
    "\n",
    "The `aggregate` methods take an extra parameter, `zero`, which fixes a subtlety in `reduce`: did you notice that the first time it was called on two elements of the list, `f(1, 2)` and every subsequent time it was called on a subtally and an element from the list, `f(f(1, 2), 3)`? That can make it awkward to write the function `f`, having to handle the two cases. The arguments to a function given to `aggregate` always take the same types.\n",
    "\n",
    "For instance, consider this cheezy histogram-filler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 8, 10, 8, 6]\n"
     ]
    }
   ],
   "source": [
    "def fill(histogram, number):\n",
    "    if 0 <= number < len(histogram):\n",
    "        return histogram[:number] + [histogram[number] + 1] + histogram[number + 1:]\n",
    "    else:\n",
    "        return histogram\n",
    "\n",
    "data = [3, 2, 4, 1, 2, 3, 1, 4, 1, 2, 3, 1, 2, 3, 0, 2, 3, 0, 1, 2, 4, 3, 2, 4, 1, 2, 3, 1, 0, 1, 2, 4, 3, 2, 4]\n",
    "\n",
    "filled = data.aggregate(fill, zero=[0, 0, 0, 0, 0])\n",
    "\n",
    "print filled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `zero` is an empty histogram; the function `fill` takes a partially filled histogram and a number from the dataset to fill it. If we had tried to do this with `reduce`, we'd have to handle the case in which `fill` is passed two numbers as arguments, rather than a histogram and a number.\n",
    "\n",
    "The last three functionals emulate loops. In this functional environment, we won't be writing any loops ourselves.\n",
    "\n",
    "   * `pairs`   TODO\n",
    "   * `table`\n",
    "   * `zip`\n",
    "\n",
    "# Playtime\n",
    "\n",
    "Now it's time to play! Let's get some CMS (public) data. And just to make sure that the fun never ends, let's get an infinite (unending) stream of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from histogrammar import *\n",
    "from histogrammar.tutorial import cmsdata\n",
    "\n",
    "def InfiniteEvents():\n",
    "    while True:\n",
    "        for event in cmsdata.EventIterator():\n",
    "            yield event\n",
    "\n",
    "events = InfiniteEvents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proxy_builtin(type(events))[\"take\"] = property(taker);                     hasattr(events, \"take\")\n",
    "proxy_builtin(type(events))[\"map\"] = property(mapper);                     hasattr(events, \"map\")\n",
    "proxy_builtin(type(events))[\"flatten\"] = property(flattener);              hasattr(events, \"flatten\")\n",
    "proxy_builtin(type(events))[\"flatmap\"] = property(flatmapper);             hasattr(events, \"flatmap\")\n",
    "proxy_builtin(type(events))[\"filter\"] = property(filterer);                hasattr(events, \"filter\")\n",
    "proxy_builtin(type(events))[\"reduce\"] = property(reducer);                 hasattr(events, \"reduce\")\n",
    "proxy_builtin(type(events))[\"aggregate\"] = property(aggregator);           hasattr(events, \"aggregate\")\n",
    "proxy_builtin(type(events))[\"reduceright\"] = property(reducerright);       hasattr(events, \"reduceright\")\n",
    "proxy_builtin(type(events))[\"aggregateright\"] = property(aggregatorright); hasattr(events, \"aggregateright\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dimuon(event):\n",
    "    mu1, mu2 = event.muons[:2]\n",
    "    return (mu1 + mu2).mass\n",
    "\n",
    "list(events.filter(lambda ev: ev.muons.size >= 2).map(dimuon).take(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def histogrammarMethod(cls):\n",
    "    def generatorProperty(lst):\n",
    "        def hargs(*args, **kwds):\n",
    "            h = cls(*args, **kwds)\n",
    "            for x in lst:\n",
    "                h.fill(x)\n",
    "            return h\n",
    "        return hargs\n",
    "    return generatorProperty\n",
    "\n",
    "proxy_builtin(type(events))[\"Average\"] = property(histogrammarMethod(Average))\n",
    "proxy_builtin(type(events))[\"Bin\"] = property(histogrammarMethod(Bin))\n",
    "proxy_builtin(type(events))[\"Categorize\"] = property(histogrammarMethod(Categorize))\n",
    "proxy_builtin(type(events))[\"CentrallyBin\"] = property(histogrammarMethod(CentrallyBin))\n",
    "proxy_builtin(type(events))[\"Label\"] = property(histogrammarMethod(Label))\n",
    "proxy_builtin(type(events))[\"Bundle\"] = property(histogrammarMethod(UntypedLabel))  # rename like HG 2.0\n",
    "proxy_builtin(type(events))[\"Index\"] = property(histogrammarMethod(Index))\n",
    "proxy_builtin(type(events))[\"Branch\"] = property(histogrammarMethod(Branch))\n",
    "proxy_builtin(type(events))[\"Count\"] = property(histogrammarMethod(Count))\n",
    "proxy_builtin(type(events))[\"Deviate\"] = property(histogrammarMethod(Deviate))\n",
    "proxy_builtin(type(events))[\"Fraction\"] = property(histogrammarMethod(Fraction))\n",
    "proxy_builtin(type(events))[\"IrregularlyBin\"] = property(histogrammarMethod(IrregularlyBin))\n",
    "proxy_builtin(type(events))[\"Minimize\"] = property(histogrammarMethod(Minimize))\n",
    "proxy_builtin(type(events))[\"Maximize\"] = property(histogrammarMethod(Maximize))\n",
    "proxy_builtin(type(events))[\"Select\"] = property(histogrammarMethod(Select))\n",
    "proxy_builtin(type(events))[\"SparselyBin\"] = property(histogrammarMethod(SparselyBin))\n",
    "proxy_builtin(type(events))[\"Stack\"] = property(histogrammarMethod(Stack))\n",
    "proxy_builtin(type(events))[\"Sum\"] = property(histogrammarMethod(Sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "th1 = events.filter(lambda ev: ev.muons.size >= 2).take(100).Bin(120, 0, 120, dimuon).plot.root(\"name\")\n",
    "th1.Draw()\n",
    "tcanvas.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
